{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = pd.read_csv('../../footy_data/championship_teams_2022.csv')\n",
    "games = pd.read_csv('../../footy_data/championship_games_2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_for_later = games\n",
    "#I am saving this new variable so it will be the original df when I want to include games that are 'incomplete' later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "games['over/under'] = np.where(games['home_team_goal_count'] + games['away_team_goal_count'] > 2.5, 1, 0)\n",
    "# Adding column 0 represents under 2.5, 1 represents over 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.loc[games['status'] == 'complete']\n",
    "#We only want games that have been completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats['avg_home_xg_for_home_team'] = \"\"\n",
    "team_stats['avg_away_xg_against_home_team'] = \"\"\n",
    "team_stats['avg_xg_for_home_team'] = \"\"\n",
    "team_stats['avg_xg_against_home_team'] = \"\"\n",
    "team_stats['avg_home_xg_for_away_team'] = \"\"\n",
    "team_stats['avg_away_xg_against_away_team'] = \"\"\n",
    "team_stats['avg_xg_for_away_team'] = \"\"\n",
    "team_stats['avg_xg_against_away_team'] = \"\"\n",
    "#Creating average xG and xGA for each team myself because FootyStats is too lazy to put it correctly in the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-2d43a3413e47>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-2d43a3413e47>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    avg_for = avg_stoke.append(games.loc[games['away_team_name'] == team_stats['common_name'][0]])\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#CODE TO FIX XG AND XGA HERE, use numpy\n",
    "#average of home_team = common_name[0]xgfor and away_team = common_name[0] xgfor\n",
    "def get_avg_xg(team):\n",
    "    avg_for = games.loc[games['home_team_name'] == team_stats[team]\n",
    "    avg_for = avg_stoke.append(games.loc[games['away_team_name'] == team_stats['common_name'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games['home_xg'] = \"\"\n",
    "games['away_xg'] = \"\"\n",
    "games['home_xg_against'] = \"\"\n",
    "games['away_xg_against'] = \"\"\n",
    "games['home_total_corners'] = \"\"\n",
    "games['away_total_corners'] = \"\"\n",
    "\n",
    "# Creating new columns where our data will go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function to help fill xg in our games df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_stats = team_stats[['common_name', 'xg_for_avg_overall']]\n",
    "corner_stats = team_stats[['common_name', 'corners_per_match']]\n",
    "xga_stats = team_stats[['common_name', 'xg_against_avg_overall']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_stats = dict(xg_stats.values)\n",
    "corner_stats = dict(corner_stats.values)\n",
    "xga_stats = dict(xga_stats.values)\n",
    "\n",
    "#By making this into dictionaries, it will be easier to call them/update them with the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_stats(team):\n",
    "    games['home_xg'] = np.where(games['home_team_name'] == team, xg_stats[team], games['home_xg'])\n",
    "    games['away_xg'] = np.where(games['away_team_name'] == team, xg_stats[team], games['away_xg'])\n",
    "    games['home_xg_against'] = np.where(games['home_team_name'] == team, xga_stats[team], games['home_xg_against'])\n",
    "    games['away_xg_against'] = np.where(games['away_team_name'] == team, xga_stats[team], games['away_xg_against'])\n",
    "    games['home_total_corners'] = np.where(games['home_team_name'] == team, corner_stats[team], games['home_total_corners'])\n",
    "    games['away_total_corners'] = np.where(games['away_team_name'] == team, corner_stats[team], games['away_total_corners'])\n",
    "    \n",
    "#Function to put team stats into games dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_stats(team_stats['common_name'][0])\n",
    "fill_stats(team_stats['common_name'][1])\n",
    "fill_stats(team_stats['common_name'][2]) \n",
    "fill_stats(team_stats['common_name'][3]) \n",
    "fill_stats(team_stats['common_name'][4]) \n",
    "fill_stats(team_stats['common_name'][5]) \n",
    "fill_stats(team_stats['common_name'][6]) \n",
    "fill_stats(team_stats['common_name'][7]) \n",
    "fill_stats(team_stats['common_name'][8]) \n",
    "fill_stats(team_stats['common_name'][9]) \n",
    "fill_stats(team_stats['common_name'][10]) \n",
    "fill_stats(team_stats['common_name'][11]) \n",
    "fill_stats(team_stats['common_name'][12]) \n",
    "fill_stats(team_stats['common_name'][13]) \n",
    "fill_stats(team_stats['common_name'][14]) \n",
    "fill_stats(team_stats['common_name'][15]) \n",
    "fill_stats(team_stats['common_name'][16]) \n",
    "fill_stats(team_stats['common_name'][17]) \n",
    "fill_stats(team_stats['common_name'][18]) \n",
    "fill_stats(team_stats['common_name'][19]) \n",
    "fill_stats(team_stats['common_name'][20]) \n",
    "fill_stats(team_stats['common_name'][21]) \n",
    "fill_stats(team_stats['common_name'][22]) \n",
    "fill_stats(team_stats['common_name'][23]) \n",
    "\n",
    "#Reading in stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in stats for new DF we'll use for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction_games['home_xg'] = \"\"\n",
    "test_prediction_games['away_xg'] = \"\"\n",
    "test_prediction_games['home_xg_against'] = \"\"\n",
    "test_prediction_games['away_xg_against'] = \"\"\n",
    "test_prediction_games['home_total_corners'] = \"\"\n",
    "test_prediction_games['away_total_corners'] = \"\"\n",
    "\n",
    "# Creating new columns where our data will go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_stats_new_test(team):\n",
    "    test_prediction_games['home_xg'] = np.where(test_prediction_games['home_team_name'] == team, xg_stats[team], test_prediction_games['home_xg'])\n",
    "    test_prediction_games['away_xg'] = np.where(test_prediction_games['away_team_name'] == team, xg_stats[team], test_prediction_games['away_xg'])\n",
    "    test_prediction_games['home_xg_against'] = np.where(test_prediction_games['home_team_name'] == team, xga_stats[team], test_prediction_games['home_xg_against'])\n",
    "    test_prediction_games['away_xg_against'] = np.where(test_prediction_games['away_team_name'] == team, xga_stats[team], test_prediction_games['away_xg_against'])\n",
    "    test_prediction_games['home_total_corners'] = np.where(test_prediction_games['home_team_name'] == team, corner_stats[team], test_prediction_games['home_total_corners'])\n",
    "    test_prediction_games['away_total_corners'] = np.where(test_prediction_games['away_team_name'] == team, corner_stats[team], test_prediction_games['away_total_corners'])\n",
    "    \n",
    "#Function to put team stats into games dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_stats_new_test('Fulham')\n",
    "fill_stats_new_test('Blackburn Rovers')\n",
    "fill_stats_new_test('West Bromwich Albion')\n",
    "fill_stats_new_test('Queens Park Rangers')\n",
    "fill_stats_new_test('AFC Bournemouth')\n",
    "fill_stats_new_test('Middlesbrough')\n",
    "fill_stats_new_test('Barnsley')\n",
    "fill_stats_new_test('Millwall')\n",
    "fill_stats_new_test('Sheffield United')\n",
    "fill_stats_new_test('Reading')\n",
    "fill_stats_new_test('Cardiff City')\n",
    "fill_stats_new_test('Nottingham Forest')\n",
    "fill_stats_new_test('Hull City')\n",
    "fill_stats_new_test('Blackpool')\n",
    "fill_stats_new_test('Luton Town')\n",
    "fill_stats_new_test('Stoke City')\n",
    "fill_stats_new_test('Swansea City')\n",
    "fill_stats_new_test('Derby County')\n",
    "fill_stats_new_test('Huddersfield Town')\n",
    "fill_stats_new_test('Preston North End')\n",
    "fill_stats_new_test('Coventry City')\n",
    "fill_stats_new_test('Peterborough United')\n",
    "fill_stats_new_test('Birmingham City')\n",
    "fill_stats_new_test('Bristol City')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some more EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.corr()['over/under'].sort_values(ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's do some modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be a 'normal' model in which we use train_test_split to divide up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['home_xg', 'away_xg', 'home_xg_against', 'away_xg_against']\n",
    "X = games[features]\n",
    "y = games['over/under']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the test set while it is trained on the original train set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['home_xg', 'away_xg', 'home_xg_against', 'away_xg_against']\n",
    "X = test_prediction_games[features]\n",
    "y = test_prediction_games['over/under']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.9, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[0:5]['home_team_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to set the train and test sets myself without train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Over/Under 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# games = pd.read_csv('../footy_data/championship_games_2022.csv')\n",
    "#Going to load this in again because I need the full dataset including incomplete games -- the ones I want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['home_xg', 'away_xg', 'home_xg_against', 'away_xg_against']\n",
    "X_train = games[0:72][features]\n",
    "X_test = games[72:84][features]\n",
    "y_train = games[0:72]['over/under']\n",
    "y_test = games[72:84]['over/under']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next need to add something to track accuracy from week to week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
